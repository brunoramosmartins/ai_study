{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring\n",
    "In this lesson, you will infer sentiment and topics from product reviews and news articles.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamp_review = \"\"\"\n",
    "Precisava de uma luminária legal para o meu quarto, e essa tinha \\\n",
    "armazenamento adicional e um preço não muito alto. \\\n",
    "Entendi rápido. O barbante da nossa lâmpada quebrou durante o \\\n",
    "trânsito e a empresa enviou alegremente um novo. \\\n",
    "Veio dentro de alguns dias também. Foi fácil colocar \\\n",
    "junto. Eu tinha uma peça faltando, então entrei em contato com o \\\n",
    "suporte e eles rapidamente me deram a peça que faltava! \\\n",
    "A Lumina me parece ser uma grande empresa que se importa \\\n",
    "sobre seus clientes e produtos!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment (positive/negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O sentimento da análise é positivo e satisfeito com o produto e o atendimento da empresa.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Qual é o sentimento da seguinte análise do produto,\n",
    "que é delimitado com backticks triplos?\n",
    "\n",
    "Texto da revisão: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivo.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Qual é o sentimento da seguinte análise do produto,\n",
    "que é delimitado com backticks triplos?\n",
    "\n",
    "Dê sua resposta como uma única palavra, seja \"positivo\" \\\n",
    "ou \"negativo\".\n",
    "\n",
    "Texto da revisão:'''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify types of emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satisfeito, feliz, grato, impressionado, confiante\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifique uma lista de emoções que o escritor do \\\n",
    "seguinte revisão está expressando. Não inclua mais de \\\n",
    "cinco itens na lista. Formate sua resposta como uma lista de \\\n",
    "palavras minúsculas separadas por vírgulas.\n",
    "\n",
    "Texto da revisão: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "O autor da resenha a seguir está expressando raiva?\\\n",
    "A revisão é delimitada por acentos graves triplos. \\\n",
    "Dê sua resposta como sim ou não.\n",
    "\n",
    "Texto da revisão:'''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract product and company name from customer reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Item\": \"luminária\",\n",
      "  \"Marca\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifique os seguintes itens do texto de revisão:\n",
    "- Item comprado pelo revisor\n",
    "- Empresa que fez o item\n",
    "\n",
    "A revisão é delimitada por acentos graves triplos. \\\n",
    "Formate sua resposta como um objeto JSON com \\\n",
    "\"Item\" e \"Marca\" como chaves.\n",
    "Se a informação não estiver presente, use \"desconhecido\" \\\n",
    "como o valor.\n",
    "Faça sua resposta o mais curta possível.\n",
    "  \n",
    "Texto da revisão: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing multiple tasks at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Sentiment\": \"positivo\",\n",
      "  \"Anger\": false,\n",
      "  \"Item\": \"luminária com armazenamento adicional\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifique os seguintes itens do texto de revisão:\n",
    "- Sentimento (positivo ou negativo)\n",
    "- O revisor está expressando raiva? (verdadeiro ou falso)\n",
    "- Item comprado pelo revisor\n",
    "- Empresa que fez o item\n",
    "\n",
    "A revisão é delimitada por acentos graves triplos. \\\n",
    "Formate sua resposta como um objeto JSON com \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" e \"Brand\" como as chaves.\n",
    "Se a informação não estiver presente, use \"desconhecido\" \\\n",
    "como o valor.\n",
    "Faça sua resposta o mais curta possível.\n",
    "Formate o valor Anger como um booleano.\n",
    "\n",
    "Texto da revisão:'''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "Em uma pesquisa recente realizada pelo governo,\n",
    "funcionários do setor público foram solicitados a avaliar seu nível\n",
    "de satisfação com o departamento em que trabalham.\n",
    "Os resultados revelaram que a NASA foi o mais popular\n",
    "departamento com um índice de satisfação de 95%.\n",
    "\n",
    "Um funcionário da NASA, John Smith, comentou sobre as descobertas,\n",
    "afirmando: \"Não estou surpreso que a NASA saiu por cima.\n",
    "É um ótimo lugar para trabalhar com pessoas incríveis e\n",
    "oportunidades incríveis. tenho orgulho de fazer parte\n",
    "uma organização tão inovadora.\"\n",
    "\n",
    "Os resultados também foram bem recebidos pela equipe de gerenciamento da NASA,\n",
    "com o diretor Tom Johnson afirmando: \"Estamos entusiasmados em\n",
    "ouvir que nossos funcionários estão satisfeitos com seu trabalho na NASA.\n",
    "Temos uma equipe talentosa e dedicada que trabalha incansavelmente\n",
    "para alcançar nossos objetivos, e é fantástico ver que seus\n",
    "o trabalho árduo está valendo a pena.\"\n",
    "\n",
    "A pesquisa também revelou que o\n",
    "Administração da Previdência Social teve a menor satisfação\n",
    "classificação, com apenas 45% dos funcionários indicando que eram\n",
    "satisfeitos com seu trabalho. O governo se comprometeu a\n",
    "abordar as preocupações levantadas pelos funcionários na pesquisa e\n",
    "trabalhar para melhorar a satisfação no trabalho em todos os departamentos.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer 5 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Pesquisa de satisfação no setor público\n",
      "2. Departamentos com maior e menor índice de satisfação\n",
      "3. Comentários de funcionários da NASA sobre a pesquisa\n",
      "4. Reação da equipe de gerenciamento da NASA aos resultados\n",
      "5. Compromisso do governo em melhorar a satisfação no trabalho em todos os departamentos.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine cinco tópicos que estão sendo discutidos no \\\n",
    "seguinte texto, que é delimitado por crases triplos.\n",
    "\n",
    "Faça com que cada item tenha uma ou duas palavras.\n",
    "\n",
    "Formate sua resposta como uma lista de itens separados por vírgulas.\n",
    "\n",
    "Exemplo de texto: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Pesquisa de satisfação no setor público\\n2. Departamentos com maior e menor índice de satisfação\\n3. Comentários de funcionários da NASA sobre a pesquisa\\n4. Reação da equipe de gerenciamento da NASA aos resultados\\n5. Compromisso do governo em melhorar a satisfação no trabalho em todos os departamentos.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.split(sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = [\n",
    "    \"nasa\", \"local government\", \"engineering\", \n",
    "    \"employee satisfaction\", \"federal government\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a news alert for certain topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nasa: 1\n",
      "local government: 0\n",
      "engineering: 0\n",
      "employee satisfaction: 1\n",
      "federal government: 1\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine se cada item na seguinte lista de \\\n",
    "tópicos é um tópico no texto abaixo, que\n",
    "é delimitado com acentos graves triplos.\n",
    "\n",
    "Dê sua resposta como uma lista com 0 ou 1 para cada tópico.\\\n",
    "\n",
    "Lista de tópicos: {\", \".join(topic_list)}\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT: New NASA story!\n"
     ]
    }
   ],
   "source": [
    "topic_dict = {i.split(': ')[0]: int(i.split(': ')[1]) for i in response.split(sep='\\n')}\n",
    "if topic_dict['nasa'] == 1:\n",
    "    print(\"ALERT: New NASA story!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try experimenting on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
